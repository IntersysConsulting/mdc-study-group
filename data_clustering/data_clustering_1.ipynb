{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Clustering\n",
    "\n",
    "Data clustering is a process of assigning a set of records into subsets, called clusters, such that records in the same cluster are similar and records in different clusters are quite disctinct.\n",
    "\n",
    "A typical clustering process involves the following five steps:\n",
    "\n",
    "1. pattern representation;\n",
    "2. dissimilarity measure definition;\n",
    "3. clustering;\n",
    "4. data abstraction;\n",
    "5. assesment of output\n",
    "\n",
    "In this interactive session, we will be reviewing the *k-means* algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The *k-means* Algorithm\n",
    "\n",
    "The *k-means* algorithm is the most popular and the simplest partitional clustering algorithm. It has many variations. This exercise will review the standard algorithm.\n",
    "\n",
    "### Description of the Algorithm\n",
    "\n",
    "Let $X = \\left\\{ \\mathbf{x}_0, \\mathbf{x}_1, \\cdots, \\mathbf{x}_{n - 1} \\right\\}$ be a numeric dataset containing $n$ records and $k$ be an integer in $\\{1, 2, \\cdots, n\\}$. The *k-means* algorithm tries to divide the dataset into $k$ clusters $C_0$, $C_1$, $\\cdots$, and $C_{k - 1}$ by minimizing the following objective function:\n",
    "$$E = \\sum_{i = 0}^{k - 1}\\sum_{\\mathbf{x} \\in C_i} D(\\mathbf{x}, \\boldsymbol{\\mu}_i),$$\n",
    "where $D(\\cdot, \\cdot)$ is a distance measure and $\\boldsymbol{\\mu}_i$ is the mean of cluster $C_i$, i.e.,\n",
    "$$\\boldsymbol{\\mu}_i = \\frac{1}{\\lvert C_i \\rvert} \\sum_{\\mathbf{x} \\in C_i}\\mathbf{x}$$\n",
    "\n",
    "Let $\\gamma_i$ be the cluster membership of record $\\mathbf{x}_i$ for $i = 0$, $1$, $\\cdots$, $n - 1$. That is, $\\gamma_i = j$ if $\\mathbf{x}_i$ belongs to cluster $C_j$. Then the objective function can be rewritten as:\n",
    "$$E = \\sum_{i = 0}^{n - 1}D(\\mathbf{x}_i, \\boldsymbol{\\mu}_{\\gamma_i})$$\n",
    "\n",
    "To minimize the objective function, the *k-means* algorithm employs an iterative process. At the beginning, the *k-means* algorithm selects $k$ random records from the dataset $X$ as initial cluster centers.\n",
    "\n",
    "Suppose $\\boldsymbol{\\mu}_0^{(0)}$, $\\boldsymbol{\\mu}_1^{(0)}$, $\\cdots$, and $\\boldsymbol{\\mu}_{k - 1}^{(0)}$ are the initial cluster centers. Based on these cluster centers, the *k-means* algorithm updates the cluster memberships $\\gamma_0^{(0)}$, $\\gamma_1^{(0)}$, $\\gamma_{n - 1}^{(0)}$ as follows:\n",
    "\\begin{equation}\n",
    "\\label{membership-update}\n",
    "\\gamma_i^{(0)} = \\underset{0 \\leq j \\leq k - 1}{\\operatorname{argmin}} D(\\mathbf{x}_i, \\boldsymbol{\\mu}_j^{(0)})\n",
    "\\end{equation}\n",
    "where $\\operatorname{argmin}$ is the argument that minimizes the distance. That is, $\\gamma_i^{(0)}$ is set to the index of the cluster to which $\\mathbf{x}_i$ has the smallest distance.\n",
    "\n",
    "Based on the cluster memberships $\\gamma_0^{(0)}$, $\\gamma_1^{(0)}$, $\\gamma_{n - 1}^{(0)}$, the *k-means* algorithm updates the cluster centers as follows:\n",
    "\\begin{equation}\n",
    "\\label{center-update}\n",
    "\\boldsymbol{\\boldsymbol{\\mu}}_j^{(1)} = \\frac{1}{\\left| \\left\\{ i \\mid \\gamma_i^{(0)} = j\\right\\} \\right|} \\sum_{i = 0, \\gamma_i^{(0)} = j}\\mathbf{x}_i, \\qquad\\text{$j = 0$, $1$, $\\cdots$, $k - 1$}\n",
    "\\end{equation}\n",
    "\n",
    "Then the *k-means* algorithm repeats updating the cluster memberships based on Equation \\ref{membership-update} and \\ref{center-update}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### To practice your Python\n",
    "\n",
    "1. From the datasets card in trello, use data.tar.gz to get the file with name 600points.csv.\n",
    "2. Use the kmeans implementation from scikit-learn to run the algorithm for k = 3 clusters and a max of 100 iterations. You can install that using pip (`$ pip install scikit-learn`) or anaconda, (`$ conda install scikit-learn`).    \n",
    "3. Use python's [docopt](https://github.com/docopt/docopt) or `argparse` (available in the standard library) to parse the following command line options:\n",
    "\n",
    "    ```\n",
    "    Allowed options:\n",
    "      --help                produce help message\n",
    "      --datafile arg        the data file\n",
    "      --k arg (=3)          number of clusters\n",
    "      --maxiter arg (=100)  maximum number of iterations\n",
    "    ```\n",
    "\n",
    "4. Implement the algorithm by yourself and compare with the results obtained with scikit-learn.\n",
    "5. Use [numba](https://numba.pydata.org/) to try to improve the performance of your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "node_nteract"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": true
  },
  "nteract": {
   "version": "0.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
